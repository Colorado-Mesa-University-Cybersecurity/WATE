{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weight_avg_trees import LinearModel, weight_avg_2, weight_avg_4, weight_avg_8, regular\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device_in_use = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14447\n",
      "3096\n",
      "3097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "#reading in dataset\n",
    "ch = fetch_california_housing()\n",
    "df = pd.DataFrame(data=ch.data, columns=ch.feature_names)\n",
    "\n",
    "df_train, df_temp = train_test_split(df, train_size=.70, random_state=42)\n",
    "df_val, df_test = train_test_split(df_temp, train_size=.5, random_state=42)\n",
    "\n",
    "print(df_train.shape[0])\n",
    "print(df_val.shape[0])\n",
    "print(df_test.shape[0])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.features = dataframe.drop('MedInc', axis=1).values\n",
    "        self.labels = dataframe['MedInc'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float), torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "train_dataset = CustomDataset(df_train)\n",
    "val_dataset = CustomDataset(df_val)\n",
    "test_dataset = CustomDataset(df_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to move an entire dataset to the device in advance\n",
    "def preload_dataset_to_device(loader, batch_size, device):\n",
    "    preloaded_data = [(inputs.to(device), targets.to(device)) for inputs, targets in loader]\n",
    "    return DataLoader(preloaded_data, batch_size=batch_size)\n",
    "\n",
    "# Preload datasets to device (if they fit into your device memory)\n",
    "train_loader = preload_dataset_to_device(train_loader, len(train_dataset), device_in_use)\n",
    "val_loader = preload_dataset_to_device(val_loader, len(val_dataset), device_in_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [2:05:02<00:00,  1.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional: 196.44563788416386 199.17977393808368\n",
      "Weight Avg 2 Base Models: 118.64311773900985 139.12516133189243\n",
      "Weight Avg 4 Base Models: 71.95023518414497 87.7739766108237\n",
      "Weight Avg 8 Base Models: 43.446090750408175 53.67336261702516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_size = 7  \n",
    "output_size = 1  \n",
    "\n",
    "train_loss_traditional = []\n",
    "test_loss_traditional = []\n",
    "\n",
    "train_loss_2 = []\n",
    "test_loss_2 = []\n",
    "\n",
    "train_loss_4 = []\n",
    "test_loss_4 = []\n",
    "\n",
    "train_loss_8 = []\n",
    "test_loss_8 = []\n",
    "\n",
    "#105 is the lcm(3,7,15)\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(10000)):\n",
    "\n",
    "    testloss, trainloss = regular(105, train_loader, val_loader, input_size, output_size, device_in_use) \n",
    "\n",
    "    train_loss_traditional.append(trainloss) \n",
    "    test_loss_traditional.append(testloss)\n",
    "\n",
    "    testloss, trainloss = weight_avg_2(105, train_loader, val_loader, input_size, output_size, device_in_use) \n",
    "\n",
    "    train_loss_2.append(trainloss) \n",
    "    test_loss_2.append(testloss)\n",
    "\n",
    "    testloss, trainloss = weight_avg_4(105, train_loader, val_loader, input_size, output_size, device_in_use) \n",
    "\n",
    "    train_loss_4.append(trainloss) \n",
    "    test_loss_4.append(testloss)\n",
    "\n",
    "    testloss, trainloss = weight_avg_8(105, train_loader, val_loader, input_size, output_size, device_in_use) \n",
    "\n",
    "    train_loss_8.append(trainloss) \n",
    "    test_loss_8.append(testloss)\n",
    "\n",
    "\n",
    "print(\"Traditional:\",np.mean(test_loss_traditional),np.std(test_loss_traditional))\n",
    "print(\"Weight Avg 2 Base Models:\",np.mean(test_loss_2),np.std(train_loss_2))\n",
    "print(\"Weight Avg 4 Base Models:\",np.mean(test_loss_4),np.std(train_loss_4))\n",
    "print(\"Weight Avg 8 Base Models:\",np.mean(test_loss_8),np.std(train_loss_8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
